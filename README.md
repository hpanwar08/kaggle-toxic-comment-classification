# Toxic Comment Classification Challenge

This repo contains the code that I wrote for Kaggle NLP challenge - [Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## About the challenge (from Kaggle)
In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.

## Tools required
1. _Python 3.5+_
2. _NLTK_
3. _Numpy_
4. _Pandas_
5. _Sklearn_
5. _Keras_
6. _Tensorflow_
7. _Glove word embedding_
8. _Fasttext word embedding_